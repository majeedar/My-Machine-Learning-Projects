{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.experimental import enable_iterative_imputer  # Enable experimental feature\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(418, 11)\n",
      "Train dataframe columns:  Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Test dataframe columns:  Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "train_df = pd.read_csv(\"C:/Git_files/Obesity_ML_case/train.csv\")\n",
    "test_df = pd.read_csv(\"C:/Git_files/Obesity_ML_case/test.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "print(\"Train dataframe columns: \", train_df.columns)\n",
    "print(\"Test dataframe columns: \", test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "# Create separate survived from dataset\n",
    "y_df = train_df[['Survived']].copy()\n",
    "train_only_df = train_df.drop(columns='Survived')\n",
    "print(train_only_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 11)\n",
      "   PassengerId  Pclass                                               Name  \\\n",
      "0            1       3                            Braund, Mr. Owen Harris   \n",
      "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2            3       3                             Heikkinen, Miss. Laina   \n",
      "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4            5       3                           Allen, Mr. William Henry   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
      "4    male  35.0      0      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate train and test datasets\n",
    "full_df = pd.concat([train_only_df, test_df], ignore_index=False)\n",
    "\n",
    "print(full_df.shape)\n",
    "\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1309 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Pclass       1309 non-null   int64  \n",
      " 2   Name         1309 non-null   object \n",
      " 3   Sex          1309 non-null   object \n",
      " 4   Age          1046 non-null   float64\n",
      " 5   SibSp        1309 non-null   int64  \n",
      " 6   Parch        1309 non-null   int64  \n",
      " 7   Ticket       1309 non-null   object \n",
      " 8   Fare         1308 non-null   float64\n",
      " 9   Cabin        295 non-null    object \n",
      " 10  Embarked     1307 non-null   object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 122.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataframes\n",
    "\n",
    "print(full_df.columns)\n",
    "print(full_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass     Sex   Age  SibSp  Parch            Ticket     Fare  \\\n",
      "0            1       3    male  22.0      1      0         A/5 21171   7.2500   \n",
      "1            2       1  female  38.0      1      0          PC 17599  71.2833   \n",
      "2            3       3  female  26.0      0      0  STON/O2. 3101282   7.9250   \n",
      "3            4       1  female  35.0      1      0            113803  53.1000   \n",
      "4            5       3    male  35.0      0      0            373450   8.0500   \n",
      "\n",
      "  Cabin Embarked      lname  title                                 fnames  \n",
      "0   NaN        S     Braund    Mr.                            Owen Harris  \n",
      "1   C85        C    Cumings   Mrs.  John Bradley (Florence Briggs Thayer)  \n",
      "2   NaN        S  Heikkinen  Miss.                                  Laina  \n",
      "3  C123        S   Futrelle   Mrs.          Jacques Heath (Lily May Peel)  \n",
      "4   NaN        S      Allen    Mr.                          William Henry  \n"
     ]
    }
   ],
   "source": [
    "# Split name into \"Last Name\" and \"Rest\" using \", \" as the delimiter\n",
    "full_df[['lname', 'rest']] = full_df['Name'].str.split(\", \", expand=True)\n",
    "\n",
    "# Further split \"Rest\" into \"Title\" and \"First Name(s)\" using the first space\n",
    "full_df[['title', 'fnames']] = full_df['rest'].str.split(\" \", n=1, expand=True)\n",
    "\n",
    "# Drop the original \"Name\" and \"Rest\" columns (if not needed)\n",
    "full_df = full_df.drop(columns=['Name', 'rest'])\n",
    "\n",
    "print(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Title  Count\n",
      "0         Mr.    757\n",
      "1       Miss.    260\n",
      "2        Mrs.    197\n",
      "3     Master.     61\n",
      "4        Rev.      8\n",
      "5         Dr.      8\n",
      "6        Col.      4\n",
      "7       Mlle.      2\n",
      "8      Major.      2\n",
      "9         Ms.      2\n",
      "10      Lady.      1\n",
      "11       Sir.      1\n",
      "12       Mme.      1\n",
      "13       Don.      1\n",
      "14      Capt.      1\n",
      "15        the      1\n",
      "16  Jonkheer.      1\n",
      "17      Dona.      1\n"
     ]
    }
   ],
   "source": [
    "# Get the unique titles\n",
    "title_counts = full_df['title'].value_counts()\n",
    "title_df = pd.DataFrame({\n",
    "    'Title': title_counts.index,\n",
    "    'Count': title_counts.values})\n",
    "\n",
    "print(title_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              lname  Count\n",
      "105         Larsson      2\n",
      "106           Angle      2\n",
      "107            Carr      2\n",
      "108          Betros      2\n",
      "109          Snyder      2\n",
      "..              ...    ...\n",
      "233         Spencer      2\n",
      "234            Cook      2\n",
      "235           Pears      2\n",
      "236  de Messemaeker      2\n",
      "237         Christy      2\n",
      "\n",
      "[133 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the unique last names\n",
    "name_counts = full_df['lname'].value_counts()\n",
    "name_counts_df = pd.DataFrame({\n",
    "    'lname': name_counts.index,\n",
    "    'Count': name_counts.values})\n",
    "\n",
    "print(name_counts_df[name_counts_df['Count'] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass     Sex   Age  SibSp  Parch            Ticket     Fare  \\\n",
      "0            1       3    male  22.0      1      0         A/5 21171   7.2500   \n",
      "1            2       1  female  38.0      1      0          PC 17599  71.2833   \n",
      "2            3       3  female  26.0      0      0  STON/O2. 3101282   7.9250   \n",
      "3            4       1  female  35.0      1      0            113803  53.1000   \n",
      "4            5       3    male  35.0      0      0            373450   8.0500   \n",
      "\n",
      "  Cabin Embarked      lname  title                                 fnames  \\\n",
      "0   NaN        S     Braund    Mr.                            Owen Harris   \n",
      "1   C85        C    Cumings   Mrs.  John Bradley (Florence Briggs Thayer)   \n",
      "2   NaN        S  Heikkinen  Miss.                                  Laina   \n",
      "3  C123        S   Futrelle   Mrs.          Jacques Heath (Lily May Peel)   \n",
      "4   NaN        S      Allen    Mr.                          William Henry   \n",
      "\n",
      "   family_size  \n",
      "0            1  \n",
      "1            2  \n",
      "2            1  \n",
      "3            2  \n",
      "4            1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Group by 'lname' and 'Ticket' to find family groups\n",
    "family_groups = full_df.groupby(['lname', 'Ticket'])\n",
    "\n",
    "# Create a 'family_size' column to record the size of the family group\n",
    "full_df['family_size'] = family_groups['lname'].transform('count')  # Selecting 'lname' or any other column\n",
    "\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  deck rest2\n",
      "0    U     0\n",
      "1    C    85\n",
      "2    U     0\n",
      "3    C   123\n",
      "4    U     0\n",
      "5    U     0\n",
      "6    E    46\n",
      "7    U     0\n",
      "8    U     0\n",
      "9    U     0\n"
     ]
    }
   ],
   "source": [
    "# Create cabin number for missing values\n",
    "full_df.loc[full_df.Cabin.isnull(), 'Cabin'] = 'U0'\n",
    "\n",
    "# Create deck and room number columns\n",
    "# Extracting the first letter as 'Deck' and the rest as 'Room Number'\n",
    "full_df['deck'] = full_df['Cabin'].str[0]\n",
    "full_df['rest2'] = full_df['Cabin'].str[1:]\n",
    "\n",
    "print(full_df[['deck','rest2']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass     Sex   Age  SibSp  Parch            Ticket     Fare  \\\n",
      "0            1       3    male  22.0      1      0         A/5 21171   7.2500   \n",
      "1            2       1  female  38.0      1      0          PC 17599  71.2833   \n",
      "2            3       3  female  26.0      0      0  STON/O2. 3101282   7.9250   \n",
      "3            4       1  female  35.0      1      0            113803  53.1000   \n",
      "4            5       3    male  35.0      0      0            373450   8.0500   \n",
      "\n",
      "  Cabin Embarked      lname  title                                 fnames  \\\n",
      "0    U0        S     Braund    Mr.                            Owen Harris   \n",
      "1   C85        C    Cumings   Mrs.  John Bradley (Florence Briggs Thayer)   \n",
      "2    U0        S  Heikkinen  Miss.                                  Laina   \n",
      "3  C123        S   Futrelle   Mrs.          Jacques Heath (Lily May Peel)   \n",
      "4    U0        S      Allen    Mr.                          William Henry   \n",
      "\n",
      "   family_size deck     rest2  room  \n",
      "0            1    U    0nostr     0  \n",
      "1            2    C   85nostr    85  \n",
      "2            1    U    0nostr     0  \n",
      "3            2    C  123nostr   123  \n",
      "4            1    U    0nostr     0  \n"
     ]
    }
   ],
   "source": [
    "# add additional elements rest column\n",
    "full_df['rest2'] = full_df['rest2'] + ' nostr'\n",
    "\n",
    "# Replace irregular numbers with real number\n",
    "full_df['rest2'] = full_df['rest2'].str.replace(' G73', '373')\n",
    "full_df['rest2'] = full_df['rest2'].str.replace(' E69', '269')\n",
    "full_df['rest2'] = full_df['rest2'].str.replace(' G63', '363')\n",
    "full_df['rest2'] = full_df['rest2'].str.replace(' E46', '246')\n",
    "full_df['rest2'] = full_df['rest2'].str.replace(' E57', '257')\n",
    "\n",
    "# Remove spaces\n",
    "full_df['rest2'] = full_df['rest2'].str.replace(' ', '')\n",
    "\n",
    "# Define a function to extract the first numeric element from a string\n",
    "def extract_first_numeric(s):\n",
    "    match = re.search(r'\\d+', s)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to the 'rest2' column to create the 'room' column\n",
    "full_df['room'] = full_df['rest2'].apply(extract_first_numeric).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group low-occurring, related titles together\n",
    "full_df.loc[full_df['title'] == 'Jonkheer.', 'title'] = 'Master.'\n",
    "full_df.loc[full_df['title'].isin(['Ms.', 'Mlle.']), 'title'] = 'Miss.'\n",
    "full_df.loc[full_df['title'] == 'Mme.', 'title'] = 'Mrs.'\n",
    "full_df.loc[full_df['title'].isin(['Capt.', 'Don.', 'Major.', 'Col.', 'Sir.']), 'title'] = 'Sir.'\n",
    "full_df.loc[full_df['title'].isin(['Dona.', 'Lady.', 'the']), 'title'] = 'Lady.'\n",
    "\n",
    "# Print categories of title\n",
    "print(pd.DataFrame({\n",
    "    'Title': full_df['title'].value_counts().index,\n",
    "    'Count': full_df['title'].value_counts().values\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1309 entries, 0 to 417\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Pclass       1309 non-null   int64  \n",
      " 2   Sex          1309 non-null   object \n",
      " 3   Age          1046 non-null   float64\n",
      " 4   SibSp        1309 non-null   int64  \n",
      " 5   Parch        1309 non-null   int64  \n",
      " 6   Ticket       1309 non-null   object \n",
      " 7   Fare         1308 non-null   float64\n",
      " 8   Cabin        1309 non-null   object \n",
      " 9   Embarked     1307 non-null   object \n",
      " 10  lname        1309 non-null   object \n",
      " 11  title        1309 non-null   object \n",
      " 12  fnames       1309 non-null   object \n",
      " 13  family_size  1309 non-null   int64  \n",
      " 14  deck         1309 non-null   object \n",
      " 15  rest2        1309 non-null   object \n",
      " 16  room         1309 non-null   int32  \n",
      "dtypes: float64(2), int32(1), int64(5), object(9)\n",
      "memory usage: 179.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(full_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     group_id\n",
      "0         721\n",
      "1         817\n",
      "2         915\n",
      "3          66\n",
      "4         650\n",
      "..        ...\n",
      "413       712\n",
      "414       835\n",
      "415       873\n",
      "416       580\n",
      "417       263\n",
      "\n",
      "[1309 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create group IDs based on Ticket number\n",
    "# Group by 'Ticket' and assign group IDs\n",
    "full_df['group_id'] = full_df.groupby('Ticket').ngroup().add(1)\n",
    "\n",
    "# Count the occurrences of each group_id\n",
    "group_id_counts = full_df['group_id'].value_counts()\n",
    "\n",
    "# Get the group_ids where count is 1\n",
    "group_ids_to_replace = group_id_counts[group_id_counts == 1].index.tolist()\n",
    "\n",
    "\n",
    "print(full_df[['group_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NAs per column, full_df:  PassengerId      0\n",
      "Pclass           0\n",
      "Sex              0\n",
      "Age            263\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin            0\n",
      "Embarked         2\n",
      "lname            0\n",
      "title            0\n",
      "fnames           0\n",
      "family_size      0\n",
      "deck             0\n",
      "rest2            0\n",
      "room             0\n",
      "group_id         0\n",
      "dtype: int64\n",
      "Percentage of NAs per column, full_df:  PassengerId     0.000000\n",
      "Pclass          0.000000\n",
      "Sex             0.000000\n",
      "Age            20.091673\n",
      "SibSp           0.000000\n",
      "Parch           0.000000\n",
      "Ticket          0.000000\n",
      "Fare            0.076394\n",
      "Cabin           0.000000\n",
      "Embarked        0.152788\n",
      "lname           0.000000\n",
      "title           0.000000\n",
      "fnames          0.000000\n",
      "family_size     0.000000\n",
      "deck            0.000000\n",
      "rest2           0.000000\n",
      "room            0.000000\n",
      "group_id        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check NAs in each column\n",
    "print(\"Number of NAs per column, full_df: \", full_df.isna().sum())\n",
    "print(\"Percentage of NAs per column, full_df: \", full_df.isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NAs per column, full_df:  PassengerId      0\n",
      "Pclass           0\n",
      "Sex              0\n",
      "Age            263\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin            0\n",
      "Embarked         2\n",
      "lname            0\n",
      "title            0\n",
      "fnames           0\n",
      "family_size      0\n",
      "deck             0\n",
      "rest2            0\n",
      "room             0\n",
      "group_id         0\n",
      "dtype: int64\n",
      "Percentage of NAs per column, full_df:  PassengerId     0.000000\n",
      "Pclass          0.000000\n",
      "Sex             0.000000\n",
      "Age            20.091673\n",
      "SibSp           0.000000\n",
      "Parch           0.000000\n",
      "Ticket          0.000000\n",
      "Fare            0.076394\n",
      "Cabin           0.000000\n",
      "Embarked        0.152788\n",
      "lname           0.000000\n",
      "title           0.000000\n",
      "fnames          0.000000\n",
      "family_size     0.000000\n",
      "deck            0.000000\n",
      "rest2           0.000000\n",
      "room            0.000000\n",
      "group_id        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fill NAs except Age\n",
    "group_fare = full_df.groupby('group_id')['Fare'].transform('mean')\n",
    "\n",
    "# Fill missing values in the 'Fare' column with the group fare\n",
    "full_df['Fare'] = full_df['Fare'].fillna(group_fare)\n",
    "\n",
    "# Display the DataFrame after filling missing values\n",
    "print(\"Number of NAs per column, full_df: \", full_df.isna().sum())\n",
    "print(\"Percentage of NAs per column, full_df: \", full_df.isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass     Sex  Age  SibSp  Parch  Ticket     Fare Cabin  \\\n",
      "5              6       3    male  NaN      0      0  330877   8.4583    U0   \n",
      "17            18       2    male  NaN      0      0  244373  13.0000    U0   \n",
      "19            20       3  female  NaN      0      0    2649   7.2250    U0   \n",
      "26            27       3    male  NaN      0      0    2631   7.2250    U0   \n",
      "28            29       3  female  NaN      0      0  330959   7.8792    U0   \n",
      "..           ...     ...     ...  ...    ...    ...     ...      ...   ...   \n",
      "470          471       3    male  NaN      0      0  323592   7.2500    U0   \n",
      "475          476       1    male  NaN      0      0  110465  52.0000   A14   \n",
      "481          482       2    male  NaN      0      0  239854   0.0000    U0   \n",
      "485          486       3  female  NaN      3      1    4133  25.4667    U0   \n",
      "490          491       3    male  NaN      1      0   65304  19.9667    U0   \n",
      "\n",
      "    Embarked       lname  title                   fnames  family_size deck  \\\n",
      "5          Q       Moran    Mr.                    James            1    U   \n",
      "17         S    Williams    Mr.           Charles Eugene            1    U   \n",
      "19         C  Masselmani   Mrs.                   Fatima            1    U   \n",
      "26         C        Emir    Mr.            Farred Chehab            1    U   \n",
      "28         Q     O'Dwyer  Miss.           Ellen \"Nellie\"            1    U   \n",
      "..       ...         ...    ...                      ...          ...  ...   \n",
      "470        S       Keefe    Mr.                   Arthur            1    U   \n",
      "475        S    Clifford    Mr.            George Quincy            1    A   \n",
      "481        S       Frost    Mr.    Anthony Wood \"Archie\"            1    U   \n",
      "485        S     Lefebre  Miss.                  Jeannie            5    U   \n",
      "490        S     Hagland    Mr.  Konrad Mathias Reiersen            1    U   \n",
      "\n",
      "       rest2  room  group_id  \n",
      "5     0nostr     0       374  \n",
      "17    0nostr     0       202  \n",
      "19    0nostr     0       244  \n",
      "26    0nostr     0       239  \n",
      "28    0nostr     0       386  \n",
      "..       ...   ...       ...  \n",
      "470   0nostr     0       369  \n",
      "475  14nostr    14         3  \n",
      "481   0nostr     0       180  \n",
      "485   0nostr     0       672  \n",
      "490   0nostr     0       682  \n",
      "\n",
      "[100 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check Age NAs\n",
    "age_nas = full_df[full_df['Age'].isna()]\n",
    "print(age_nas.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1309 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Pclass       1309 non-null   int64  \n",
      " 1   Sex          1309 non-null   object \n",
      " 2   Age          1046 non-null   float64\n",
      " 3   SibSp        1309 non-null   int64  \n",
      " 4   Parch        1309 non-null   int64  \n",
      " 5   Fare         1308 non-null   float64\n",
      " 6   Embarked     1307 non-null   object \n",
      " 7   title        1309 non-null   object \n",
      " 8   family_size  1309 non-null   int64  \n",
      " 9   deck         1309 non-null   object \n",
      " 10  room         1309 non-null   int32  \n",
      " 11  group_id     1309 non-null   int64  \n",
      "dtypes: float64(2), int32(1), int64(5), object(4)\n",
      "memory usage: 127.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Drop irrelevant columns\n",
    "# Create list of columns to drop\n",
    "columns_to_drop = ['PassengerId', 'Ticket', 'Cabin', 'lname', 'fnames', 'rest2']\n",
    "\n",
    "# Drop columns\n",
    "full_df1 = full_df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(full_df1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NAs per column, full_df:  Pclass           0\n",
      "Sex              0\n",
      "Age            263\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Fare             1\n",
      "Embarked         0\n",
      "title            0\n",
      "family_size      0\n",
      "deck             0\n",
      "room             0\n",
      "group_id         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill NAs in Embarked feature with the most frequent value\n",
    "most_frequent_embarked = full_df1['Embarked'].mode().iloc[0]\n",
    "\n",
    "# Fill missing values in the 'Embarked' column with the most frequent value\n",
    "full_df1['Embarked'] = full_df1['Embarked'].fillna(most_frequent_embarked)\n",
    "\n",
    "# Check NAs in each column\n",
    "print(\"Number of NAs per column, full_df: \", full_df1.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket',\n",
      "       'Fare', 'Cabin', 'Embarked', 'lname', 'title', 'fnames', 'family_size',\n",
      "       'deck', 'rest2', 'room', 'group_id'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1309 entries, 0 to 417\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Pclass       1309 non-null   int64  \n",
      " 2   Sex          1309 non-null   object \n",
      " 3   Age          1046 non-null   float64\n",
      " 4   SibSp        1309 non-null   int64  \n",
      " 5   Parch        1309 non-null   int64  \n",
      " 6   Ticket       1309 non-null   object \n",
      " 7   Fare         1308 non-null   float64\n",
      " 8   Cabin        1309 non-null   object \n",
      " 9   Embarked     1307 non-null   object \n",
      " 10  lname        1309 non-null   object \n",
      " 11  title        1309 non-null   object \n",
      " 12  fnames       1309 non-null   object \n",
      " 13  family_size  1309 non-null   int64  \n",
      " 14  deck         1309 non-null   object \n",
      " 15  rest2        1309 non-null   object \n",
      " 16  room         1309 non-null   int32  \n",
      " 17  group_id     1309 non-null   int64  \n",
      "dtypes: float64(2), int32(1), int64(6), object(9)\n",
      "memory usage: 189.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(full_df.columns)\n",
    "print(full_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dummies for categorical columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'title',\n",
      "       'family_size', 'deck', 'room', 'group_id', 'Sex_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables for Sex column\n",
    "full_df2 = pd.get_dummies(full_df1, columns=[\"Sex\"], drop_first=True)\n",
    "\n",
    "print(full_df2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for the specified columns\n",
    "full_df3 = pd.get_dummies(full_df2, columns=[\"Embarked\", \"title\", \"deck\"], drop_first=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass   Age  SibSp  Parch     Fare  family_size  room  group_id  Sex_male  \\\n",
      "0       3  22.0      1      0   7.2500            1     0       721      True   \n",
      "1       1  38.0      1      0  71.2833            2    85       817     False   \n",
      "2       3  26.0      0      0   7.9250            1     0       915     False   \n",
      "3       1  35.0      1      0  53.1000            2   123        66     False   \n",
      "4       3  35.0      0      0   8.0500            1     0       650      True   \n",
      "\n",
      "   Embarked_C  ...  title_the  deck_A  deck_B  deck_C  deck_D  deck_E  deck_F  \\\n",
      "0       False  ...      False   False   False   False   False   False   False   \n",
      "1        True  ...      False   False   False    True   False   False   False   \n",
      "2       False  ...      False   False   False   False   False   False   False   \n",
      "3       False  ...      False   False   False    True   False   False   False   \n",
      "4       False  ...      False   False   False   False   False   False   False   \n",
      "\n",
      "   deck_G  deck_T  deck_U  \n",
      "0   False   False    True  \n",
      "1   False   False   False  \n",
      "2   False   False    True  \n",
      "3   False   False   False  \n",
      "4   False   False    True  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the column names to see the dummy variables\n",
    "print(full_df3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create afunction for impute NAs\n",
    "\n",
    "def impute_na(data):\n",
    "    # Create an IterativeImputer with default estimator (BayesianRidge)\n",
    "    imputer = IterativeImputer(max_iter=20, random_state=42)\n",
    "\n",
    "    # Fit the imputer to the DataFrame and transform it to fill in missing values\n",
    "    data_imputed = imputer.fit_transform(data)\n",
    "\n",
    "    # Create a new DataFrame with the imputed values, keeping the original column names\n",
    "    data_imputed_df = pd.DataFrame(data_imputed, columns=data.columns)\n",
    "    \n",
    "    return data_imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass             0.0\n",
      "Age                0.0\n",
      "SibSp              0.0\n",
      "Parch              0.0\n",
      "Fare               0.0\n",
      "family_size        0.0\n",
      "room               0.0\n",
      "group_id           0.0\n",
      "Sex_male           0.0\n",
      "Embarked_C         0.0\n",
      "Embarked_Q         0.0\n",
      "Embarked_S         0.0\n",
      "title_Capt.        0.0\n",
      "title_Col.         0.0\n",
      "title_Don.         0.0\n",
      "title_Dona.        0.0\n",
      "title_Dr.          0.0\n",
      "title_Jonkheer.    0.0\n",
      "title_Lady.        0.0\n",
      "title_Major.       0.0\n",
      "title_Master.      0.0\n",
      "title_Miss.        0.0\n",
      "title_Mlle.        0.0\n",
      "title_Mme.         0.0\n",
      "title_Mr.          0.0\n",
      "title_Mrs.         0.0\n",
      "title_Ms.          0.0\n",
      "title_Rev.         0.0\n",
      "title_Sir.         0.0\n",
      "title_the          0.0\n",
      "deck_A             0.0\n",
      "deck_B             0.0\n",
      "deck_C             0.0\n",
      "deck_D             0.0\n",
      "deck_E             0.0\n",
      "deck_F             0.0\n",
      "deck_G             0.0\n",
      "deck_T             0.0\n",
      "deck_U             0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "full_df4= impute_na(full_df3)\n",
    "print(full_df4.isna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_df1: (891, 39)\n",
      "Shape of X_test_df1: (418, 39)\n"
     ]
    }
   ],
   "source": [
    "# Split full_df into training and testing sets\n",
    "X_train_df1 = full_df4.iloc[:891]  # First 891 rows for training\n",
    "X_test_df1 = full_df4.iloc[891:]   # Last 418 rows for testing\n",
    "\n",
    "# Reset index of X_test_df1\n",
    "X_test_df1 = X_test_df1.reset_index(drop=True)\n",
    "\n",
    "# Verify the shapes of the resulting DataFrames\n",
    "print(\"Shape of X_train_df1:\", X_train_df1.shape)\n",
    "print(\"Shape of X_test_df1:\", X_test_df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass        Age  SibSp  Parch      Fare  family_size   room  group_id  \\\n",
      "0       3.0  34.500000    0.0    0.0    7.8292          1.0    0.0     377.0   \n",
      "1       3.0  47.000000    1.0    0.0    7.0000          1.0    0.0     583.0   \n",
      "2       2.0  62.000000    0.0    0.0    9.6875          1.0    0.0     185.0   \n",
      "3       3.0  27.000000    0.0    0.0    8.6625          1.0    0.0     367.0   \n",
      "4       3.0  22.000000    1.0    1.0   12.2875          2.0    0.0     339.0   \n",
      "..      ...        ...    ...    ...       ...          ...    ...       ...   \n",
      "413     3.0  28.927151    0.0    0.0    8.0500          1.0    0.0     712.0   \n",
      "414     1.0  39.000000    0.0    0.0  108.9000          1.0  105.0     835.0   \n",
      "415     3.0  38.500000    0.0    0.0    7.2500          1.0    0.0     873.0   \n",
      "416     3.0  28.643903    0.0    0.0    8.0500          1.0    0.0     580.0   \n",
      "417     3.0   3.421430    1.0    1.0   22.3583          3.0    0.0     263.0   \n",
      "\n",
      "     Sex_male  Embarked_C  ...  title_the  deck_A  deck_B  deck_C  deck_D  \\\n",
      "0         1.0         0.0  ...        0.0     0.0     0.0     0.0     0.0   \n",
      "1         0.0         0.0  ...        0.0     0.0     0.0     0.0     0.0   \n",
      "2         1.0         0.0  ...        0.0     0.0     0.0     0.0     0.0   \n",
      "3         1.0         0.0  ...        0.0     0.0     0.0     0.0     0.0   \n",
      "4         0.0         0.0  ...        0.0     0.0     0.0     0.0     0.0   \n",
      "..        ...         ...  ...        ...     ...     ...     ...     ...   \n",
      "413       1.0         0.0  ...        0.0     0.0     0.0     0.0     0.0   \n",
      "414       0.0         1.0  ...        0.0     0.0     0.0     1.0     0.0   \n",
      "415       1.0         0.0  ...        0.0     0.0     0.0     0.0     0.0   \n",
      "416       1.0         0.0  ...        0.0     0.0     0.0     0.0     0.0   \n",
      "417       1.0         1.0  ...        0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "     deck_E  deck_F  deck_G  deck_T  deck_U  \n",
      "0       0.0     0.0     0.0     0.0     1.0  \n",
      "1       0.0     0.0     0.0     0.0     1.0  \n",
      "2       0.0     0.0     0.0     0.0     1.0  \n",
      "3       0.0     0.0     0.0     0.0     1.0  \n",
      "4       0.0     0.0     0.0     0.0     1.0  \n",
      "..      ...     ...     ...     ...     ...  \n",
      "413     0.0     0.0     0.0     0.0     1.0  \n",
      "414     0.0     0.0     0.0     0.0     0.0  \n",
      "415     0.0     0.0     0.0     0.0     1.0  \n",
      "416     0.0     0.0     0.0     0.0     1.0  \n",
      "417     0.0     0.0     0.0     0.0     1.0  \n",
      "\n",
      "[418 rows x 39 columns]\n",
      "     PassengerId  Pclass                                          Name  \\\n",
      "0            892       3                              Kelly, Mr. James   \n",
      "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                     Myles, Mr. Thomas Francis   \n",
      "3            895       3                              Wirz, Mr. Albert   \n",
      "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "..           ...     ...                                           ...   \n",
      "413         1305       3                            Spector, Mr. Woolf   \n",
      "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                           Ware, Mr. Frederick   \n",
      "417         1309       3                      Peter, Master. Michael J   \n",
      "\n",
      "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
      "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
      "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
      "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
      "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
      "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
      "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
      "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
      "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
      "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
      "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
      "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
      "\n",
      "[418 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_df1)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (891, 39)\n",
      "X_test: (418, 39)\n",
      "y_train: (891,)\n"
     ]
    }
   ],
   "source": [
    "#### Create X_train, y-train and X_test narrays ready for scaling and modelling\n",
    "# Convert DataFrames to numpy arrays\n",
    "X_train = X_train_df1.values\n",
    "X_test = X_test_df1.values\n",
    "y_train = np.ravel(y_df)\n",
    "\n",
    "# Verify the conversion\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a function for scaling the DataFrame\n",
    "def scale_dataset1(data):\n",
    "    # Initialize the MinMaxScaler with the desired feature range\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # Fit the scaler to the data and transform it\n",
    "    X_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    # Return the scaled data\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the training and test dataset\n",
    "X_train_scaled = scale_dataset1(X_train)\n",
    "X_test_scaled = scale_dataset1(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KFold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Define the models to be used\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(), \n",
    "    'Logistic regression' : LogisticRegression(max_iter=5000),\n",
    "    'Naive Bayes' : GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results (mean accuracy):\n",
      "KNN: 0.6936\n",
      "Random Forest: 0.8283\n",
      "Decision Tree: 0.7812\n",
      "SVM: 0.6745\n",
      "Logistic regression: 0.8249\n",
      "Naive Bayes: 0.7576\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models with unscaled variables\n",
    "model_results = {}\n",
    "for model_name, model in models.items():\n",
    "    # Use cross_val_score to evaluate the pipeline with KFold\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    model_results[model_name] = scores.mean()  # Store the mean accuracy of the model\n",
    "\n",
    "print(\"Cross-validation results (mean accuracy):\")\n",
    "for model_name, mean_score in model_results.items():\n",
    "    print(f\"{model_name}: {mean_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results (mean accuracy):\n",
      "KNN: 0.7777\n",
      "Random Forest: 0.8260\n",
      "Decision Tree: 0.7778\n",
      "SVM: 0.8171\n",
      "Logistic regression: 0.8260\n",
      "Naive Bayes: 0.7296\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models with scaled variables\n",
    "model_results = {}\n",
    "for model_name, model in models.items():\n",
    "    # Use cross_val_score to evaluate the pipeline with KFold\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='accuracy')\n",
    "    model_results[model_name] = scores.mean()  # Store the mean accuracy of the model\n",
    "\n",
    "print(\"Cross-validation results (mean accuracy):\")\n",
    "for model_name, mean_score in model_results.items():\n",
    "    print(f\"{model_name}: {mean_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "243 fits failed out of a total of 486.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "184 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "59 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.81481481 0.81593715 0.81818182\n",
      " 0.82828283 0.83277217 0.82828283 0.82940516 0.83950617 0.83164983\n",
      " 0.83164983 0.82716049 0.82716049 0.82940516 0.82603816 0.82828283\n",
      " 0.83164983 0.83164983 0.83501684 0.82379349 0.82491582 0.82491582\n",
      " 0.82042649 0.82603816 0.82491582 0.82716049 0.82491582 0.82491582\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83164983 0.82379349 0.82716049\n",
      " 0.82603816 0.82828283 0.82828283 0.82828283 0.8305275  0.82940516\n",
      " 0.82379349 0.8305275  0.83613917 0.82042649 0.82828283 0.8305275\n",
      " 0.83164983 0.8338945  0.82491582 0.82603816 0.82940516 0.82828283\n",
      " 0.82042649 0.83164983 0.82491582 0.82828283 0.83164983 0.8338945\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.8305275  0.81930415 0.81930415\n",
      " 0.82603816 0.82940516 0.82940516 0.83277217 0.84399551 0.83277217\n",
      " 0.82716049 0.82603816 0.82828283 0.83501684 0.8305275  0.8305275\n",
      " 0.82828283 0.83164983 0.83164983 0.82042649 0.82603816 0.82491582\n",
      " 0.82491582 0.81930415 0.82603816 0.81818182 0.82379349 0.82716049]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best score: 0.8439955106621774\n"
     ]
    }
   ],
   "source": [
    "# Define a Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define a parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "}\n",
    "# Define a GridSearchCV instance\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "243 fits failed out of a total of 486.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "143 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.81930415 0.81930415 0.81593715\n",
      " 0.82379349 0.82267116 0.82491582 0.82491582 0.84175084 0.83277217\n",
      " 0.82491582 0.83277217 0.82491582 0.83277217 0.82940516 0.8338945\n",
      " 0.82603816 0.8305275  0.83164983 0.81930415 0.82603816 0.82379349\n",
      " 0.82603816 0.82042649 0.82491582 0.82042649 0.82603816 0.82379349\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.81930415 0.81481481 0.83277217\n",
      " 0.82603816 0.82828283 0.82379349 0.83277217 0.83613917 0.82828283\n",
      " 0.82716049 0.83277217 0.83164983 0.82603816 0.82940516 0.8305275\n",
      " 0.82267116 0.82828283 0.82940516 0.83164983 0.82042649 0.82491582\n",
      " 0.82828283 0.82379349 0.82267116 0.81818182 0.82267116 0.82379349\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.82154882 0.82042649 0.82154882\n",
      " 0.82042649 0.82828283 0.82603816 0.82716049 0.82603816 0.83164983\n",
      " 0.82379349 0.83277217 0.82716049 0.83277217 0.82828283 0.82940516\n",
      " 0.82940516 0.83277217 0.83613917 0.82940516 0.82379349 0.82379349\n",
      " 0.83164983 0.83277217 0.82940516 0.82154882 0.82828283 0.82491582]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best score: 0.8417508417508417\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid-search to scaled data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best score: 0.8249158249158249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "720 fits failed out of a total of 2160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 80, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.67901235        nan 0.67901235 0.73737374 0.75869809 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.67901235        nan 0.67901235 0.73737374 0.77553311 0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.67901235        nan 0.67901235 0.73737374 0.75869809 0.67789001\n",
      "        nan        nan 0.67564534        nan 0.79124579 0.67789001\n",
      " 0.67901235        nan 0.67901235 0.73737374 0.77553311 0.67901235\n",
      "        nan        nan 0.67564534        nan 0.81144781 0.67901235\n",
      " 0.67901235        nan 0.67901235 0.73737374 0.75869809 0.67789001\n",
      "        nan        nan 0.67901235        nan 0.79124579 0.67789001\n",
      " 0.67901235        nan 0.67901235 0.73737374 0.77553311 0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.69472503        nan 0.69472503 0.75982043 0.77216611 0.6969697\n",
      "        nan        nan 0.6969697         nan 0.79573513 0.6969697\n",
      " 0.69472503        nan 0.69472503 0.75982043 0.78900112 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.69472503        nan 0.69472503 0.75982043 0.77216611 0.69584736\n",
      "        nan        nan 0.69584736        nan 0.79573513 0.6969697\n",
      " 0.69472503        nan 0.69472503 0.75982043 0.78900112 0.7037037\n",
      "        nan        nan 0.6969697         nan 0.81369248 0.7037037\n",
      " 0.69472503        nan 0.69472503 0.75982043 0.77216611 0.6969697\n",
      "        nan        nan 0.69472503        nan 0.79573513 0.69584736\n",
      " 0.69472503        nan 0.69472503 0.75982043 0.78900112 0.7037037\n",
      "        nan        nan 0.69472503        nan 0.81369248 0.7037037\n",
      " 0.78002245        nan 0.67789001 0.79910213 0.79573513 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.78002245        nan 0.67676768 0.79910213 0.80583614 0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.78002245        nan 0.67789001 0.79910213 0.79573513 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.78114478        nan 0.67676768 0.79910213 0.80583614 0.67901235\n",
      "        nan        nan 0.67676768        nan 0.81144781 0.67901235\n",
      " 0.78002245        nan 0.67789001 0.79910213 0.79573513 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.78002245        nan 0.67676768 0.79910213 0.80583614 0.67901235\n",
      "        nan        nan 0.67676768        nan 0.81144781 0.67901235\n",
      " 0.79910213        nan 0.69584736 0.80808081 0.80808081 0.6969697\n",
      "        nan        nan 0.6969697         nan 0.79573513 0.6969697\n",
      " 0.7979798         nan 0.69584736 0.80808081 0.8013468  0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.7979798         nan 0.69584736 0.80808081 0.80808081 0.6969697\n",
      "        nan        nan 0.6969697         nan 0.79573513 0.6969697\n",
      " 0.7979798         nan 0.69584736 0.80808081 0.8013468  0.7037037\n",
      "        nan        nan 0.6969697         nan 0.81369248 0.7037037\n",
      " 0.7979798         nan 0.69584736 0.80808081 0.80808081 0.6969697\n",
      "        nan        nan 0.69584736        nan 0.79573513 0.6969697\n",
      " 0.7979798         nan 0.69584736 0.80808081 0.8013468  0.7037037\n",
      "        nan        nan 0.69584736        nan 0.81369248 0.7037037\n",
      " 0.82379349        nan 0.67789001 0.81369248 0.81369248 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.82379349        nan 0.67789001 0.81369248 0.8047138  0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.82379349        nan 0.67789001 0.81369248 0.81369248 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.82491582        nan 0.67901235 0.81369248 0.8047138  0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.82379349        nan 0.67789001 0.81369248 0.81369248 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.82491582        nan 0.67901235 0.81369248 0.8047138  0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.82267116        nan 0.6969697  0.81930415 0.80695847 0.6969697\n",
      "        nan        nan 0.6969697         nan 0.79573513 0.6969697\n",
      " 0.82267116        nan 0.7037037  0.81930415 0.81032548 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.82267116        nan 0.6969697  0.81930415 0.80695847 0.6969697\n",
      "        nan        nan 0.6969697         nan 0.79573513 0.6969697\n",
      " 0.82267116        nan 0.7037037  0.81930415 0.81032548 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.82267116        nan 0.69584736 0.81930415 0.80695847 0.6969697\n",
      "        nan        nan 0.69584736        nan 0.79573513 0.6969697\n",
      " 0.82267116        nan 0.7037037  0.81930415 0.81032548 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.81705948        nan 0.67789001 0.81705948 0.80695847 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.81818182        nan 0.67901235 0.81705948 0.81032548 0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.81705948        nan 0.67789001 0.81705948 0.80695847 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.81705948        nan 0.67901235 0.81705948 0.81032548 0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.81818182        nan 0.67789001 0.81705948 0.80695847 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.81818182        nan 0.67901235 0.81705948 0.81032548 0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.81369248        nan 0.6969697  0.81481481 0.79910213 0.6969697\n",
      "        nan        nan 0.6969697         nan 0.79573513 0.69584736\n",
      " 0.81369248        nan 0.7037037  0.81481481 0.81032548 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.81369248        nan 0.6969697  0.81481481 0.79910213 0.6969697\n",
      "        nan        nan 0.6969697         nan 0.79573513 0.69584736\n",
      " 0.81369248        nan 0.7037037  0.81481481 0.81032548 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.81369248        nan 0.6969697  0.81481481 0.79910213 0.6969697\n",
      "        nan        nan 0.6969697         nan 0.79573513 0.6969697\n",
      " 0.81257015        nan 0.7037037  0.81481481 0.81032548 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.81705948        nan 0.67789001 0.81593715 0.78900112 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.81705948        nan 0.67901235 0.81593715 0.80583614 0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.81705948        nan 0.67789001 0.81593715 0.78900112 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.81705948        nan 0.67901235 0.81593715 0.80583614 0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.81705948        nan 0.67789001 0.81593715 0.78900112 0.67789001\n",
      "        nan        nan 0.67789001        nan 0.79124579 0.67789001\n",
      " 0.81593715        nan 0.67901235 0.81593715 0.80583614 0.67901235\n",
      "        nan        nan 0.67901235        nan 0.81144781 0.67901235\n",
      " 0.81481481        nan 0.69584736 0.81593715 0.8047138  0.6969697\n",
      "        nan        nan 0.69584736        nan 0.79573513 0.6969697\n",
      " 0.81257015        nan 0.7037037  0.81593715 0.81144781 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.81369248        nan 0.6969697  0.81593715 0.8047138  0.69584736\n",
      "        nan        nan 0.6969697         nan 0.79573513 0.6969697\n",
      " 0.81481481        nan 0.7037037  0.81593715 0.81144781 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037\n",
      " 0.81369248        nan 0.6969697  0.81593715 0.8047138  0.69584736\n",
      "        nan        nan 0.69584736        nan 0.79573513 0.6969697\n",
      " 0.81481481        nan 0.7037037  0.81593715 0.81144781 0.7037037\n",
      "        nan        nan 0.7037037         nan 0.81369248 0.7037037 ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define a basic Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Define a parameter grid for tuning\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],  # Penalties supported by different solvers\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga'],  # Compatible solvers for different penalties\n",
    "    'l1_ratio': [0, 0.5, 1],  # Used with 'elasticnet' penalty\n",
    "    'class_weight': [None, 'balanced'],  # For class imbalance\n",
    "    'max_iter': [100, 200]  # Maximum iterations\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV for Logistic Regression\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the unscaled training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'class_weight': None, 'l1_ratio': 0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score: 0.8305274971941637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "720 fits failed out of a total of 2160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 80, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.61616162        nan 0.61616162 0.75533109 0.79236813 0.79236813\n",
      "        nan        nan 0.79236813        nan 0.81705948 0.81818182\n",
      " 0.61616162        nan 0.61616162 0.75533109 0.79236813 0.79236813\n",
      "        nan        nan 0.79236813        nan 0.81705948 0.81818182\n",
      " 0.61616162        nan 0.61616162 0.75533109 0.79236813 0.79236813\n",
      "        nan        nan 0.61616162        nan 0.81705948 0.81930415\n",
      " 0.61616162        nan 0.61616162 0.75533109 0.79236813 0.79236813\n",
      "        nan        nan 0.61616162        nan 0.81705948 0.81818182\n",
      " 0.61616162        nan 0.61616162 0.75533109 0.79236813 0.79236813\n",
      "        nan        nan 0.61616162        nan 0.81705948 0.81930415\n",
      " 0.61616162        nan 0.61616162 0.75533109 0.79236813 0.79236813\n",
      "        nan        nan 0.61616162        nan 0.81705948 0.81818182\n",
      " 0.61616162        nan 0.61616162 0.79124579 0.78900112 0.78900112\n",
      "        nan        nan 0.78900112        nan 0.81593715 0.81369248\n",
      " 0.61616162        nan 0.53872054 0.79124579 0.78900112 0.78900112\n",
      "        nan        nan 0.78900112        nan 0.81593715 0.81481481\n",
      " 0.61616162        nan 0.46127946 0.79124579 0.78900112 0.78900112\n",
      "        nan        nan 0.78226712        nan 0.81593715 0.81369248\n",
      " 0.61616162        nan 0.46127946 0.79124579 0.78900112 0.78900112\n",
      "        nan        nan 0.78226712        nan 0.81593715 0.81481481\n",
      " 0.61616162        nan 0.53872054 0.79124579 0.78900112 0.78900112\n",
      "        nan        nan 0.38383838        nan 0.81593715 0.81369248\n",
      " 0.61616162        nan 0.46127946 0.79124579 0.78900112 0.78900112\n",
      "        nan        nan 0.53872054        nan 0.81593715 0.81481481\n",
      " 0.79012346        nan 0.78900112 0.80583614 0.80695847 0.80695847\n",
      "        nan        nan 0.80695847        nan 0.81705948 0.81930415\n",
      " 0.79012346        nan 0.78900112 0.80583614 0.80695847 0.80695847\n",
      "        nan        nan 0.80695847        nan 0.81705948 0.81818182\n",
      " 0.79012346        nan 0.78900112 0.80583614 0.80695847 0.80695847\n",
      "        nan        nan 0.79236813        nan 0.81705948 0.81930415\n",
      " 0.79012346        nan 0.78900112 0.80583614 0.80695847 0.80695847\n",
      "        nan        nan 0.79236813        nan 0.81705948 0.81818182\n",
      " 0.79012346        nan 0.78900112 0.80583614 0.80695847 0.80695847\n",
      "        nan        nan 0.78900112        nan 0.81705948 0.81930415\n",
      " 0.79012346        nan 0.78900112 0.80583614 0.80695847 0.80695847\n",
      "        nan        nan 0.78900112        nan 0.81705948 0.81818182\n",
      " 0.78114478        nan 0.77777778 0.79573513 0.78338945 0.78338945\n",
      "        nan        nan 0.78338945        nan 0.81593715 0.81369248\n",
      " 0.78114478        nan 0.77777778 0.79573513 0.78338945 0.78338945\n",
      "        nan        nan 0.78338945        nan 0.81593715 0.81369248\n",
      " 0.78114478        nan 0.77777778 0.79573513 0.78338945 0.78338945\n",
      "        nan        nan 0.77216611        nan 0.81593715 0.81369248\n",
      " 0.78114478        nan 0.77777778 0.79573513 0.78338945 0.78338945\n",
      "        nan        nan 0.77216611        nan 0.81593715 0.81369248\n",
      " 0.78114478        nan 0.77777778 0.79573513 0.78338945 0.78338945\n",
      "        nan        nan 0.77777778        nan 0.81593715 0.81369248\n",
      " 0.78114478        nan 0.77777778 0.79573513 0.78338945 0.78338945\n",
      "        nan        nan 0.77777778        nan 0.81593715 0.81481481\n",
      " 0.82267116        nan 0.82940516 0.82267116 0.8305275  0.8305275\n",
      "        nan        nan 0.8305275         nan 0.81705948 0.81930415\n",
      " 0.82267116        nan 0.82940516 0.82267116 0.8305275  0.8305275\n",
      "        nan        nan 0.8305275         nan 0.81705948 0.81818182\n",
      " 0.82267116        nan 0.82940516 0.82267116 0.8305275  0.8305275\n",
      "        nan        nan 0.82491582        nan 0.81705948 0.81930415\n",
      " 0.82267116        nan 0.82940516 0.82267116 0.8305275  0.8305275\n",
      "        nan        nan 0.82491582        nan 0.81705948 0.81818182\n",
      " 0.82267116        nan 0.82940516 0.82267116 0.8305275  0.8305275\n",
      "        nan        nan 0.82940516        nan 0.81705948 0.81930415\n",
      " 0.82267116        nan 0.82940516 0.82267116 0.8305275  0.8305275\n",
      "        nan        nan 0.82940516        nan 0.81705948 0.81818182\n",
      " 0.81144781        nan 0.81369248 0.81705948 0.81257015 0.81257015\n",
      "        nan        nan 0.81257015        nan 0.81593715 0.81369248\n",
      " 0.81144781        nan 0.81369248 0.81705948 0.81257015 0.81257015\n",
      "        nan        nan 0.81257015        nan 0.81593715 0.81481481\n",
      " 0.81144781        nan 0.81369248 0.81705948 0.81257015 0.81257015\n",
      "        nan        nan 0.81144781        nan 0.81593715 0.81369248\n",
      " 0.81144781        nan 0.81369248 0.81705948 0.81257015 0.81257015\n",
      "        nan        nan 0.81144781        nan 0.81593715 0.81481481\n",
      " 0.81144781        nan 0.81369248 0.81705948 0.81257015 0.81257015\n",
      "        nan        nan 0.81369248        nan 0.81593715 0.81369248\n",
      " 0.81144781        nan 0.81369248 0.81705948 0.81257015 0.81257015\n",
      "        nan        nan 0.81369248        nan 0.81593715 0.81481481\n",
      " 0.81930415        nan 0.81818182 0.82379349 0.81930415 0.81930415\n",
      "        nan        nan 0.81930415        nan 0.81705948 0.81930415\n",
      " 0.81930415        nan 0.81818182 0.82379349 0.81930415 0.81818182\n",
      "        nan        nan 0.81818182        nan 0.81705948 0.81818182\n",
      " 0.81930415        nan 0.81818182 0.82379349 0.81930415 0.81930415\n",
      "        nan        nan 0.81818182        nan 0.81705948 0.81930415\n",
      " 0.81930415        nan 0.81818182 0.82379349 0.81930415 0.81818182\n",
      "        nan        nan 0.81705948        nan 0.81705948 0.81818182\n",
      " 0.81930415        nan 0.81818182 0.82379349 0.81930415 0.81930415\n",
      "        nan        nan 0.81818182        nan 0.81705948 0.81818182\n",
      " 0.81930415        nan 0.81818182 0.82379349 0.81930415 0.81818182\n",
      "        nan        nan 0.81818182        nan 0.81705948 0.81818182\n",
      " 0.81369248        nan 0.81257015 0.81369248 0.81369248 0.81369248\n",
      "        nan        nan 0.81369248        nan 0.81593715 0.81369248\n",
      " 0.81369248        nan 0.81481481 0.81369248 0.81369248 0.81257015\n",
      "        nan        nan 0.81257015        nan 0.81593715 0.81481481\n",
      " 0.81369248        nan 0.81257015 0.81369248 0.81369248 0.81369248\n",
      "        nan        nan 0.81257015        nan 0.81593715 0.81369248\n",
      " 0.81369248        nan 0.81481481 0.81369248 0.81369248 0.81257015\n",
      "        nan        nan 0.81144781        nan 0.81593715 0.81481481\n",
      " 0.81369248        nan 0.81257015 0.81369248 0.81369248 0.81369248\n",
      "        nan        nan 0.81257015        nan 0.81593715 0.81369248\n",
      " 0.81369248        nan 0.81481481 0.81369248 0.81369248 0.81257015\n",
      "        nan        nan 0.81481481        nan 0.81593715 0.81481481\n",
      " 0.81593715        nan 0.81930415 0.81930415 0.81930415 0.81930415\n",
      "        nan        nan 0.81930415        nan 0.81705948 0.81818182\n",
      " 0.81593715        nan 0.82042649 0.81930415 0.81930415 0.81930415\n",
      "        nan        nan 0.81930415        nan 0.81705948 0.81818182\n",
      " 0.81593715        nan 0.81930415 0.81930415 0.81930415 0.81930415\n",
      "        nan        nan 0.81930415        nan 0.81705948 0.81930415\n",
      " 0.81593715        nan 0.82042649 0.81930415 0.81930415 0.81930415\n",
      "        nan        nan 0.81930415        nan 0.81705948 0.81818182\n",
      " 0.81593715        nan 0.81930415 0.81930415 0.81930415 0.81930415\n",
      "        nan        nan 0.81930415        nan 0.81705948 0.81930415\n",
      " 0.81593715        nan 0.82042649 0.81930415 0.81930415 0.81930415\n",
      "        nan        nan 0.82042649        nan 0.81705948 0.81818182\n",
      " 0.81481481        nan 0.81369248 0.81481481 0.81593715 0.81481481\n",
      "        nan        nan 0.81481481        nan 0.81593715 0.81369248\n",
      " 0.81481481        nan 0.81481481 0.81481481 0.81593715 0.81481481\n",
      "        nan        nan 0.81481481        nan 0.81593715 0.81481481\n",
      " 0.81481481        nan 0.81369248 0.81481481 0.81593715 0.81481481\n",
      "        nan        nan 0.81369248        nan 0.81593715 0.81369248\n",
      " 0.81481481        nan 0.81481481 0.81481481 0.81593715 0.81481481\n",
      "        nan        nan 0.81481481        nan 0.81593715 0.81481481\n",
      " 0.81481481        nan 0.81369248 0.81481481 0.81593715 0.81481481\n",
      "        nan        nan 0.81369248        nan 0.81593715 0.81369248\n",
      " 0.81481481        nan 0.81481481 0.81481481 0.81593715 0.81481481\n",
      "        nan        nan 0.81481481        nan 0.81593715 0.81481481]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Majeed Win10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the scaled training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n"
     ]
    }
   ],
   "source": [
    "# Train the Chosen final model\n",
    "best_model = RandomForestClassifier(max_depth= 20, max_features= 'sqrt', min_samples_leaf=1, min_samples_split= 10,\n",
    "                                       n_estimators=200)\n",
    "# fit\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set and store in a dataframe\n",
    "survived_pred = pd.DataFrame(best_model.predict(X_test), columns=['Survived'])\n",
    "\n",
    "# Create df for PassengerID\n",
    "passid_df = test_df.loc[:, ['PassengerId']]\n",
    "\n",
    "# create submission df by merging survived and passenderID dfs\n",
    "\n",
    "submission_df = pd.concat([passid_df, survived_pred], axis=1)\n",
    "\n",
    "# Verify the result\n",
    "print(submission_df.head())\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "submission_df.to_csv('submission.csv',index=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
